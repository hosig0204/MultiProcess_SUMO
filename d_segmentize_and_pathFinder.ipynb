{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this notebook\n",
    "1. Distinguish influx, outflux edges.\n",
    "2. Make segment of edges that can be considered closed flow (i.e. no junction).\n",
    "3. Search possible OD pairs (i.e. pair of influx & outflux).\n",
    "4. Then make OD filter dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to base edge information in csv format.\n",
    "str_path_df_edge_base = \"munich_motorway_v3/df_edge_base.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read edge info as dataframe.\n",
    "df_edge_base = pd.read_csv(str_path_df_edge_base, index_col= 0)\n",
    "df_edge_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of edges.\n",
    "nr_tot_edge = df_edge_base.shape[0]\n",
    "nr_tot_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique \"from(start)\" nodes and \"to(destination)\" nodes.\n",
    "lst_edge_from_unique = list(df_edge_base.edge_from.unique())\n",
    "lst_edge_to_unique = list(df_edge_base.edge_to.unique())\n",
    "\n",
    "# Check number of unique nodes both for start and destination.\n",
    "print(len(lst_edge_from_unique))\n",
    "print(len(lst_edge_to_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to produce list of junctional nodes.\n",
    "# Junctional nodes will be appeared multiple times in the columns of \"edge_from\" or \"edge_to\".\n",
    "se_count_nodes_from = df_edge_base.edge_from.value_counts() # Serise for count values of node in \"from\" column.\n",
    "se_count_nodes_to = df_edge_base.edge_to.value_counts()     # Serise for count values of node in \"to\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check!\n",
    "se_count_nodes_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check!\n",
    "se_count_nodes_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Node ids in \"from\" column that are appeared more than once.\n",
    "lst_jct_node_from_id = se_count_nodes_from[\n",
    "    se_count_nodes_from > 1\n",
    "].index.tolist()\n",
    "\n",
    "print(lst_jct_node_from_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Node ids in \"to\" column that are appeared more than once.\n",
    "lst_jct_node_to_id = se_count_nodes_to[\n",
    "    se_count_nodes_to > 1\n",
    "].index.tolist()\n",
    "\n",
    "print(lst_jct_node_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge junctional node ids.\n",
    "lst_jct_node_id = lst_jct_node_from_id + lst_jct_node_to_id\n",
    "lst_jct_node_id = list(set(lst_jct_node_id))\n",
    "print(lst_jct_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of junctional nodes.\n",
    "print(len(lst_jct_node_from_id))\n",
    "print(len(lst_jct_node_to_id))\n",
    "print(len(lst_jct_node_id))\n",
    "\n",
    "# There could be some junctional nodes that are both \"from\" and \"to\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new column for edge types: Influx, Outflux, Junctional and Interim\n",
    "df_edge_base[\"edge_type\"] = np.nan\n",
    "df_edge_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influx edges should have \"from(start)\" nodes that are not appeared in the list of \"to(destination)\" nodes.\n",
    "# At first, make mask for reverse case so that \"isin\" function can be applied. Then reverse it.\n",
    "mask_influx_inverse = df_edge_base[\"edge_from\"].isin(lst_edge_to_unique)\n",
    "mask_influx = ~mask_influx_inverse\n",
    "\n",
    "# Check number of influx edges.\n",
    "nr_influx = mask_influx[mask_influx == True].shape[0]\n",
    "nr_influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outflux edges should have \"to(destination)\" nodes that are not appeared in the list of \"from(start)\" nodes.\n",
    "# At first, make mask for reverse case so that \"isin\" function can be applied. Then reverse it.\n",
    "mask_outflux_inverse = df_edge_base[\"edge_to\"].isin(lst_edge_from_unique)\n",
    "mask_outflux = ~mask_outflux_inverse\n",
    "\n",
    "# Check number of outflux edges.\n",
    "nr_outflux = mask_outflux[mask_outflux == True].shape[0]\n",
    "nr_outflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chec if there is overlapped edges between influx & outflux.\n",
    "# There should not be \"True\" case.\n",
    "(mask_influx & mask_outflux).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define junctional edges that are adjacent to junction nodes.\n",
    "# First filter is applied to \"from\" noedes.\n",
    "mask_jct_with_from = df_edge_base[\"edge_from\"].isin(lst_jct_node_id)\n",
    "nr_jct_edge_with_from = mask_jct_with_from.value_counts()[True]\n",
    "nr_jct_edge_with_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second filter is applied to \"to\" nodes.\n",
    "mask_jct_with_to = df_edge_base[\"edge_to\"].isin(lst_jct_node_id)\n",
    "nr_jct_edge_with_to = mask_jct_with_to.value_counts()[True]\n",
    "nr_jct_edge_with_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine masks for edges adjacent to junction nodes.\n",
    "# Some edges are junctional for both \"from\" and \"to\" junction nodes.\n",
    "mask_jct_raw = (mask_jct_with_from | mask_jct_with_to) # OR gate will merge all junctional cases.\n",
    "nr_jct_edge_raw = mask_jct_raw.value_counts()[True]\n",
    "nr_jct_edge_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Influx & Outflux edges should be removed from junctional edges for future purpose.\n",
    "# In some cases, junctional edges influde both Influx & Outflux edges.\n",
    "mask_jct = (mask_jct_raw & ~(mask_influx | mask_outflux))\n",
    "nr_jct_edge = mask_jct.value_counts()[True]\n",
    "nr_jct_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for interim edges: They are not influx, outflux and junctional edges.\n",
    "mask_interim_inverse = (mask_influx | mask_outflux | mask_jct)\n",
    "mask_interim = ~mask_interim_inverse\n",
    "nr_interim = mask_interim.value_counts()[True]\n",
    "nr_interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sum of influx, outflux, junctional and interim edges coincides with total number of edges.\n",
    "(nr_influx + nr_outflux + nr_jct_edge + nr_interim) == nr_tot_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With defined masks, set proper edge type values for each edge.\n",
    "df_edge_base.loc[mask_influx, \"edge_type\"] = \"influx\"\n",
    "df_edge_base.loc[mask_outflux, \"edge_type\"] = \"outflux\"\n",
    "df_edge_base.loc[mask_interim, \"edge_type\"] = \"interim\"\n",
    "df_edge_base.loc[mask_jct, \"edge_type\"] = \"junctional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new column \"edge_type\"\n",
    "df_edge_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again edge type has been properly set.\n",
    "# No NaN!!!\n",
    "df_edge_base.edge_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import adjacency list array. This is produced by using original dataframe before merging segments.\n",
    "arr_adjList = np.load(\"munich_motorway_v3/arr_adj_multi_proc.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from adjacency list.\n",
    "df_adjList = pd.DataFrame(arr_adjList, columns=[\"stEdge\", \"desEdge\"])\n",
    "df_adjList.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a edge connected in forward direction.\n",
    "# Accepting edge id and return connected edge id.\n",
    "def connected_edge_forward (in_df_adjList:pd.DataFrame, in_df_edge_base:pd.DataFrame , in_str_edge_id:str):\n",
    "    # Get index value from df_edge_base for input edge id.\n",
    "    idx_interim_edge = in_df_edge_base[in_df_edge_base[\"edge_id\"] == in_str_edge_id].index.values[0]\n",
    "    # Return connected edge idxs for given index value. In forward direction st --> des.\n",
    "    lst_idx_connected_fw_edge = in_df_adjList[in_df_adjList[\"stEdge\"] == idx_interim_edge][\"desEdge\"].values.tolist()\n",
    "    # Return some error message when connected edges are not single or not connected.\n",
    "    if len(lst_idx_connected_fw_edge) > 1:\n",
    "        return \"NotSingle\"\n",
    "    elif len(lst_idx_connected_fw_edge) == 0:\n",
    "        return \"NotConnect\"\n",
    "    else:\n",
    "        # Return one edge id.\n",
    "        idx_connected_fw_edge = lst_idx_connected_fw_edge[0]\n",
    "        str_connected_fw_edge_id = in_df_edge_base.at[idx_connected_fw_edge, \"edge_id\"]\n",
    "        return str_connected_fw_edge_id\n",
    "\n",
    "# Function to return a edge connected in backwrad direction.\n",
    "# Accepting edge id and return connected edge id.\n",
    "def connected_edge_backward (in_df_adjList:pd.DataFrame, in_df_edge_base:pd.DataFrame , in_str_edge_id:str):\n",
    "    # Get index value from df_edge_base for input edge id.\n",
    "    idx_interim_edge = in_df_edge_base[in_df_edge_base[\"edge_id\"] == in_str_edge_id].index.values[0]\n",
    "    # Return connected edge idxs for given index value. In backward direction des --> st.\n",
    "    lst_idx_connected_bw_edge = in_df_adjList[in_df_adjList[\"desEdge\"] == idx_interim_edge][\"stEdge\"].values.tolist()\n",
    "    # Return some error message when connected edges are not single or not connected.\n",
    "    if len(lst_idx_connected_bw_edge) > 1:\n",
    "        return \"NotSingle\"\n",
    "    elif len(lst_idx_connected_bw_edge) == 0:\n",
    "        return \"NotConnect\"\n",
    "    else:\n",
    "        # Return one edge id.\n",
    "        idx_connected_bw_edge = lst_idx_connected_bw_edge[0]\n",
    "        str_connected_bw_edge_id = in_df_edge_base.at[idx_connected_bw_edge, \"edge_id\"]\n",
    "        return str_connected_bw_edge_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for exceptions.\n",
    "class notSingleConnected(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Interim edge is connected more than one edge.\")\n",
    "        \n",
    "class notConnected(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Interim edge is not connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of interime edge ids.\n",
    "lst_interim_edge_id = df_edge_base.loc[mask_interim, \"edge_id\"].values.tolist()\n",
    "lst_interim_edge_id_tmp = lst_interim_edge_id.copy()\n",
    "# List of junctional edge ids.\n",
    "lst_jct_edge_id = df_edge_base.loc[mask_jct, \"edge_id\"].values.tolist()\n",
    "# List of influx/outflux edge ids.\n",
    "lst_in_out_edge_id = df_edge_base.loc[(mask_influx | mask_outflux), \"edge_id\"].values.tolist()\n",
    "\n",
    "# Empty list for collection of interim \"segments\".\n",
    "lst_collect_interim_seg = []\n",
    "\n",
    "try:\n",
    "    \n",
    "    while True:                         # Segment list update loop.\n",
    "        \n",
    "        str_id_interim_init = lst_interim_edge_id_tmp.pop()     # Pick one interim edge id that \"segment\" contains.\n",
    "        str_id_interim_fw = str_id_interim_init                 # Copy for forward search loop.\n",
    "        str_id_interim_bw = str_id_interim_init                 # Copy for backward search loop.\n",
    "        \n",
    "        lst_interim_seg = []                                    # Empty list for collection of interim + terminal edges of \"segement\".\n",
    "        lst_interim_seg.append(str_id_interim_init)             # Add initial interim edge id.\n",
    "        \n",
    "        while True:                     # Forward search loop.\n",
    "            \n",
    "            # Get connected edge in flow direction.    \n",
    "            str_id_interim_fw = connected_edge_forward(\n",
    "                in_df_adjList= df_adjList,\n",
    "                in_df_edge_base= df_edge_base,\n",
    "                in_str_edge_id= str_id_interim_fw\n",
    "            )\n",
    "            # Some erroeneous exceptions handling.\n",
    "            if str_id_interim_fw == \"NotSingle\":\n",
    "                raise notSingleConnected\n",
    "            elif str_id_interim_fw == \"NotConnect\":\n",
    "                raise notConnected\n",
    "            \n",
    "            if str_id_interim_fw in lst_in_out_edge_id:         # If detected fw edge is influx/outflux edge,                     \n",
    "                break                                           # then, it will not included in \"segment\" edges and break this loop.       \n",
    "            \n",
    "            lst_interim_seg.append(str_id_interim_fw)           # Append it to list for collection of \"segment\" edges.\n",
    "            \n",
    "            if str_id_interim_fw in lst_jct_edge_id:            # If connected edge is one of junctional edges.\n",
    "                break                                           # then, break this loop.\n",
    "        \n",
    "        while True:                     # Backward search loop.\n",
    "            \n",
    "            # Get connected edge in inverse-flow direction.\n",
    "            str_id_interim_bw = connected_edge_backward(\n",
    "                in_df_adjList= df_adjList,\n",
    "                in_df_edge_base= df_edge_base,\n",
    "                in_str_edge_id= str_id_interim_bw                \n",
    "            )\n",
    "            # Some erroeneous exceptions handling.\n",
    "            if str_id_interim_bw == \"NotSingle\":\n",
    "                raise notSingleConnected\n",
    "            elif str_id_interim_bw == \"NotConnect\":\n",
    "                raise notConnected\n",
    "            \n",
    "            if str_id_interim_bw in lst_in_out_edge_id:         # If detected fw edge is influx/outflux edge,  \n",
    "                break                                           # then, it will not included in \"segment\" edges and break this loop.\n",
    "            \n",
    "            lst_interim_seg.insert(0, str_id_interim_bw)        # Insert it to first position in the list for collection for \"segment\" edges.\n",
    "            \n",
    "            if str_id_interim_bw in lst_jct_edge_id:            # If connected edge is one of influx/outflux/junctional edges.\n",
    "                break                                           # then, break this loop.\n",
    "        \n",
    "        lst_collect_interim_seg.append(lst_interim_seg)         # Once \"segement\" has been accomplished. Append it to collector list.\n",
    "        \n",
    "        # Remove interim edges that are already used for \"segment\". Then, go to next iteration.\n",
    "        lst_interim_edge_id_tmp = [i for i in lst_interim_edge_id_tmp if i not in lst_interim_seg]\n",
    "        \n",
    "        if len(lst_interim_edge_id_tmp) == 0:                   # Once all interim edges are used for \"segment\"\n",
    "            break                                               # then, break this loop. EOL.\n",
    "        \n",
    "except notSingleConnected as e: \n",
    "    print(\"User exception: \" + str(e))\n",
    "    \n",
    "except notConnected as e:\n",
    "    print(\"User exception: \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List contains lists containing edge_idx for \"segement\".\n",
    "print(lst_collect_interim_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of created segments.\n",
    "len(lst_collect_interim_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert list to string.\n",
    "def list2str (in_lst_str_edges:list) -> str:\n",
    "    str_joined = \" & \".join(i for i in in_lst_str_edges)\n",
    "    return str_joined\n",
    "\n",
    "# Function to convert string to list.\n",
    "def str2list (in_str_edges:str) -> list:\n",
    "    lst_split = in_str_edges.split(\" & \")\n",
    "    return lst_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new edge info dataframe with segmented edges.\n",
    "# A new column \"seg_edges\" will contains list of segmented edge ids converted as string format.\n",
    "df_edge_segmented = df_edge_base[[\"edge_id\", \"edge_from\", \"edge_to\", \"edge_type\"]].copy()\n",
    "df_edge_segmented[\"seg_edges\"] = str()\n",
    "\n",
    "# Numbering of segmented edges.\n",
    "idx_seg = 0\n",
    "\n",
    "# Loop calculation for each segment.\n",
    "for lst_seg_edges in lst_collect_interim_seg:\n",
    "    \n",
    "    # Start & End edges of segment.\n",
    "    str_stEdgeId_seg_tmp = lst_seg_edges[0]\n",
    "    str_endEdgeId_seg_tmp = lst_seg_edges[-1]\n",
    "    # Start & End nodes of segment.\n",
    "    str_stNodeId_seg_tmp = df_edge_base[df_edge_base.edge_id == str_stEdgeId_seg_tmp][\"edge_from\"].values[0]\n",
    "    str_endNodeId_seg_tmp = df_edge_base[df_edge_base.edge_id == str_endEdgeId_seg_tmp][\"edge_to\"].values[0]  \n",
    "    \n",
    "    # Mask for segmented edges.\n",
    "    mask_seg_tmp = df_edge_segmented[\"edge_id\"].isin(lst_seg_edges)\n",
    "    # Remove rows for edges that are segmented.\n",
    "    df_edge_segmented = df_edge_segmented[~mask_seg_tmp]\n",
    "    \n",
    "    # Insert row for a new segment.\n",
    "    idx_seg += 1\n",
    "    dic_seg_tmp = {\n",
    "        \"edge_id\" : f\"segment_{idx_seg}\",\n",
    "        \"edge_from\" : str_stNodeId_seg_tmp,\n",
    "        \"edge_to\" : str_endNodeId_seg_tmp,\n",
    "        \"edge_type\" : \"segment\",\n",
    "        \"seg_edges\" : list2str(lst_seg_edges)\n",
    "    }\n",
    "    df_seg_single = pd.DataFrame([list(dic_seg_tmp.values())], columns= list(dic_seg_tmp.keys()))\n",
    "    \n",
    "    # By ignoring index, original index relations will be lost !!!!\n",
    "    df_edge_segmented = pd.concat([df_edge_segmented, df_seg_single], ignore_index= True, sort= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check segmented data frame.\n",
    "df_edge_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types.\n",
    "df_edge_segmented.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of each edge type.\n",
    "df_edge_segmented.edge_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with original edge type configuration. Before segmentation.\n",
    "df_edge_base.edge_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prepare connectivity dictionary that containing posible pair of (in --> out flux),\n",
    "# lsit of influx edge idxs need to be defined.\n",
    "lst_idx_influx_edges_connect = df_edge_base[df_edge_base.edge_type == \"influx\"].index.tolist()\n",
    "print(len(lst_idx_influx_edges_connect))                # Number of influx edges.\n",
    "print(len(lst_idx_influx_edges_connect) == nr_influx)   # Check if the value is not changed from original.\n",
    "print(lst_idx_influx_edges_connect)                     # List contains INDEX number for df_edge_base !!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to return a list of connected edge idxs in forward direction.\n",
    "# Accepting list of edge idxs and return list of forward connected edge idxs.\n",
    "def connected_edge (in_df_adjList:pd.DataFrame, in_lst_idxStPoints:list) -> list:\n",
    "    \n",
    "    lst_connected = []\n",
    "        \n",
    "    for idx_stPoint in in_lst_idxStPoints:\n",
    "        \n",
    "        if idx_stPoint not in in_df_adjList[\"stEdge\"]:\n",
    "            continue\n",
    "        else:\n",
    "            lst_connected_tmp1 = in_df_adjList[in_df_adjList['stEdge'] == idx_stPoint][\"desEdge\"].values.tolist()\n",
    "            # No duplicated edge idxs.\n",
    "            lst_connected = list(set(lst_connected + lst_connected_tmp1))\n",
    "\n",
    "    return lst_connected\n",
    "\n",
    "# Function to return a list of edge idxs that are outflux.\n",
    "def fil_outflux_edge (in_df_edge_base:pd.DataFrame, in_lst_connected_edges:list) -> list:\n",
    "    \n",
    "    lst_idxDes = []\n",
    "    \n",
    "    for idx_connected in in_lst_connected_edges:\n",
    "        if in_df_edge_base.loc[idx_connected, \"edge_type\"] == \"outflux\":\n",
    "            lst_idxDes.append(idx_connected)\n",
    "            \n",
    "    return list(set(lst_idxDes)) # No duplicated edge idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to collect reachable destination edges(outflux) for each influx edge.\n",
    "lst_collect_idxDesPoints = []\n",
    "\n",
    "# Loop calculation for each influx edge.\n",
    "for idx_stPoint in lst_idx_influx_edges_connect:\n",
    "    \n",
    "    # Initialization of lists for each influx edge.\n",
    "    lst_idxStPoints_tmp1 = [idx_stPoint]    # Start point: idx of influx edge for this loop.\n",
    "    lst_idxDesPoints_tmp1 = []              # Destination points : reachable idxs of outflux edges.\n",
    "    lst_connected_hist_tmp1 = []            # History of connected edge. Revisiting same edges will not affect the results.\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        # Find all foward connected edges. Only newly found edges will be added for each step.\n",
    "        lst_connected_tmp2 = connected_edge(df_adjList, lst_idxStPoints_tmp1)\n",
    "        lst_connected_tmp2 = [i for i in lst_connected_tmp2 if i not in lst_connected_hist_tmp1]\n",
    "        # Update history of connected edge.\n",
    "        lst_connected_hist_tmp1 = list(set(lst_connected_hist_tmp1 + lst_connected_tmp2))\n",
    "        \n",
    "        # Filter out outflux edges from newly found connected edges.\n",
    "        lst_idxDes_tmp2 = fil_outflux_edge(df_edge_base, lst_connected_tmp2)\n",
    "        # Only newly found destination (outflux) edges will be added to output list.\n",
    "        lst_idxDesPoints_tmp1 = list(set(lst_idxDesPoints_tmp1 + lst_idxDes_tmp2))\n",
    "        # Start edges (points) is prepared by excluding destination edges.\n",
    "        lst_idxStPoints_tmp1 = [i for i in lst_connected_tmp2 if i not in lst_idxDes_tmp2]\n",
    "        \n",
    "        # If start edges are run out, break this loop initiated from one start index.\n",
    "        if len(lst_idxStPoints_tmp1) == 0:\n",
    "            break\n",
    "    \n",
    "    # Append list of reachable destinations (outflux idxs) to collecting list.\n",
    "    lst_collect_idxDesPoints.append(lst_idxDesPoints_tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collected lists of reachable destinations (outflux idxs) for each influx edge.\n",
    "# Will be organised with dictionary varuable. \" influx edge id : [reachable outflux edge ids], ....\"\n",
    "dic_reachable_in_out = {}\n",
    "\n",
    "# List of influx edge ids. Not INDEX nr!!!\n",
    "lst_id_influx_edges_connect = list(map(lambda x: df_edge_base.at[x,\"edge_id\"],lst_idx_influx_edges_connect))\n",
    "\n",
    "# Loop to update target dictionary.\n",
    "for idx in range(len(lst_id_influx_edges_connect)):\n",
    "    # Influx edge id.\n",
    "    id_edge_influx_tmp = lst_id_influx_edges_connect[idx]\n",
    "    # List of reachable outflux edge ids.\n",
    "    lst_edge_reachable_outflux_tmp = list(map(lambda x: df_edge_base.at[x,\"edge_id\"],lst_collect_idxDesPoints[idx]))\n",
    "    # Update dictionary element.\n",
    "    dic_reachable_in_out[id_edge_influx_tmp] = lst_edge_reachable_outflux_tmp\n",
    "\n",
    "# Check it!\n",
    "print(len(dic_reachable_in_out))\n",
    "print(dic_reachable_in_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set order for \"edge type\" new categorical column is defined.\n",
    "df_edge_segmented[\"edge_type_cat\"] = pd.Categorical(\n",
    "    df_edge_segmented[\"edge_type\"],\n",
    "    categories= [\"influx\", \"outflux\", \"junctional\", \"segment\"],\n",
    "    ordered= True\n",
    ")\n",
    "df_edge_segmented[[\"edge_type\", \"edge_type_cat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order segmented edge info dataframe with edge types.\n",
    "# Influx --> outflux --> junctional --> segement\n",
    "df_edge_seg_ordered = df_edge_segmented.sort_values(\"edge_type_cat\")\n",
    "df_edge_seg_ordered.reset_index(inplace= True, drop= True)\n",
    "df_edge_seg_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store ordered segemented edge dataframe for future purpose.\n",
    "df_edge_seg_ordered.to_pickle(\"munich_motorway_v3/df_edge_seg_ordered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OD value creation, OD filter dataframe is defined.\n",
    "# An element of the dataframe will be set to 1 only in case of reachable influx-outflux pair.\n",
    "\n",
    "# List of ordered-segmented edge ids.\n",
    "lst_ordered_edge_id = df_edge_seg_ordered.edge_id.values.tolist()\n",
    "len_od = len(lst_ordered_edge_id)\n",
    "\n",
    "# Set initial zero value dataframe with edge ids dimensions.\n",
    "arr_od_zros = np.zeros((len_od,len_od))\n",
    "df_od_fil = pd.DataFrame(arr_od_zros, index= lst_ordered_edge_id, columns= lst_ordered_edge_id)\n",
    "\n",
    "# Set 1 for possible pair of influx-outflux.\n",
    "for id_influx, lst_id_outflux in dic_reachable_in_out.items():\n",
    "    \n",
    "    for id_outflux in lst_id_outflux:\n",
    "        df_od_fil.at[id_influx, id_outflux] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check it!\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(df_od_fil.values)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reachable pairs.\n",
    "df_od_fil.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save OD filter \n",
    "df_od_fil.to_pickle(\"munich_motorway_v3/df_od_fil.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safely stored?\n",
    "df_tmp = pd.read_pickle(\"munich_motorway_v3/df_od_fil.pkl\")\n",
    "all(df_od_fil == df_tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
